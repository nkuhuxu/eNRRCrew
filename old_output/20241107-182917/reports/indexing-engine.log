18:29:17,778 graphrag.config.read_dotenv INFO Loading pipeline .env file
18:29:17,785 graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "gpt-4o-mini",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": "https://api.chatanywhere.tech/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": ".",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input/markdown",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.md$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": true,
        "raw_entities": false,
        "top_level_nodes": true
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://api.chatanywhere.tech/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
18:29:17,800 graphrag.index.create_pipeline_config INFO skipping workflows 
18:29:17,802 graphrag.index.run INFO Running pipeline
18:29:17,802 graphrag.index.storage.file_pipeline_storage INFO Creating file storage at output\20241107-182917\artifacts
18:29:17,804 graphrag.index.input.load_input INFO loading input from root_dir=input/markdown
18:29:17,804 graphrag.index.input.load_input INFO using file storage for input
18:29:17,805 graphrag.index.storage.file_pipeline_storage INFO search input\markdown for files matching .*\.md$
18:29:17,808 graphrag.index.input.text INFO found text files from input/markdown, found [('abstract.md', {})]
18:29:17,822 graphrag.index.input.text INFO Found 1 files, loading 1
18:29:17,826 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
18:29:17,827 graphrag.index.run INFO Final # of rows loaded: 1
18:29:18,132 graphrag.index.run INFO Running workflow: create_base_text_units...
18:29:18,132 graphrag.index.run INFO dependencies for create_base_text_units: []
18:29:18,138 datashaper.workflow.workflow INFO executing verb orderby
18:29:18,152 datashaper.workflow.workflow INFO executing verb zip
18:29:18,157 datashaper.workflow.workflow INFO executing verb aggregate_override
18:29:18,187 datashaper.workflow.workflow INFO executing verb chunk
18:29:18,420 datashaper.workflow.workflow INFO executing verb select
18:29:18,429 datashaper.workflow.workflow INFO executing verb unroll
18:29:18,449 datashaper.workflow.workflow INFO executing verb rename
18:29:18,454 datashaper.workflow.workflow INFO executing verb genid
18:29:18,461 datashaper.workflow.workflow INFO executing verb unzip
18:29:18,467 datashaper.workflow.workflow INFO executing verb copy
18:29:18,474 datashaper.workflow.workflow INFO executing verb filter
18:29:18,515 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
18:29:18,979 graphrag.index.run INFO Running workflow: create_base_extracted_entities...
18:29:18,979 graphrag.index.run INFO dependencies for create_base_extracted_entities: ['create_base_text_units']
18:29:18,980 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
18:29:19,93 datashaper.workflow.workflow INFO executing verb entity_extract
18:29:19,101 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.chatanywhere.tech/v1
18:29:19,909 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4o-mini: TPM=0, RPM=0
18:29:19,909 graphrag.index.llm.load_llm INFO create concurrency limiter for gpt-4o-mini: 25
18:29:33,51 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:29:33,57 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 13.077999999979511. input_tokens=3868, output_tokens=1111
18:29:34,350 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:29:34,351 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 14.35999999998603. input_tokens=3868, output_tokens=1251
18:29:35,180 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:29:35,181 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 15.25. input_tokens=3868, output_tokens=1306
18:29:36,245 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:29:36,246 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 16.26500000001397. input_tokens=3868, output_tokens=1215
18:29:36,294 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:29:36,296 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 16.32799999997951. input_tokens=3868, output_tokens=1215
18:29:37,7 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:29:37,8 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 17.04700000002049. input_tokens=3868, output_tokens=1267
18:29:38,179 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:29:38,184 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 18.265999999945052. input_tokens=3867, output_tokens=1384
18:29:38,701 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:29:38,702 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 18.71799999999348. input_tokens=3869, output_tokens=1436
18:29:38,958 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:29:38,960 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 18.95299999997951. input_tokens=3596, output_tokens=1610
18:29:39,16 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:29:39,19 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 19.015999999945052. input_tokens=3868, output_tokens=1476
18:29:39,897 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:29:39,900 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 19.95400000002701. input_tokens=3868, output_tokens=1544
18:29:40,143 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:29:40,144 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 7.094000000040978. input_tokens=34, output_tokens=534
18:29:40,630 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:29:40,631 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 5.453000000095926. input_tokens=34, output_tokens=408
18:29:41,957 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:29:41,959 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 22.016000000061467. input_tokens=3868, output_tokens=1407
18:29:43,252 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:29:43,254 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 8.906000000075437. input_tokens=34, output_tokens=688
18:29:43,468 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:29:43,470 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 6.468999999924563. input_tokens=34, output_tokens=466
18:29:44,407 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:29:44,408 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 8.109000000054948. input_tokens=34, output_tokens=651
18:29:44,928 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:29:44,929 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 6.218999999924563. input_tokens=34, output_tokens=465
18:29:45,177 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:29:45,182 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 6.98499999998603. input_tokens=34, output_tokens=544
18:29:46,69 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:29:46,70 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 6.170999999972992. input_tokens=34, output_tokens=450
18:29:47,244 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:29:47,247 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 8.21799999999348. input_tokens=34, output_tokens=629
18:29:48,465 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:29:48,467 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 9.5. input_tokens=34, output_tokens=599
18:29:48,566 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:29:48,569 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 28.608999999938533. input_tokens=3868, output_tokens=2300
18:29:48,638 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:29:48,639 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 6.672000000020489. input_tokens=34, output_tokens=479
18:29:48,667 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:29:48,669 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 12.422000000020489. input_tokens=34, output_tokens=961
18:29:59,257 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:29:59,261 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 10.688000000081956. input_tokens=34, output_tokens=803
18:29:59,280 datashaper.workflow.workflow INFO executing verb merge_graphs
18:29:59,328 datashaper.workflow.workflow INFO executing verb snapshot_rows
18:29:59,333 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_extracted_entities.parquet
18:29:59,679 graphrag.index.run INFO Running workflow: create_summarized_entities...
18:29:59,679 graphrag.index.run INFO dependencies for create_summarized_entities: ['create_base_extracted_entities']
18:29:59,679 graphrag.index.run INFO read table from storage: create_base_extracted_entities.parquet
18:29:59,707 datashaper.workflow.workflow INFO executing verb summarize_descriptions
18:30:01,438 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:01,440 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.577999999979511. input_tokens=294, output_tokens=63
18:30:01,459 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:01,460 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.577999999979511. input_tokens=284, output_tokens=68
18:30:01,509 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:01,511 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5940000000409782. input_tokens=286, output_tokens=65
18:30:01,527 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:01,528 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.687999999965541. input_tokens=306, output_tokens=63
18:30:01,557 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:01,570 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.7179999999934807. input_tokens=278, output_tokens=74
18:30:01,595 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:01,598 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.7349999999860302. input_tokens=281, output_tokens=77
18:30:01,767 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:01,768 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.8440000000409782. input_tokens=295, output_tokens=85
18:30:01,797 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:01,798 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:01,800 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.875. input_tokens=309, output_tokens=90
18:30:01,801 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.9689999999245629. input_tokens=292, output_tokens=87
18:30:01,829 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:01,830 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.9060000000754371. input_tokens=299, output_tokens=89
18:30:01,858 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:01,859 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.9839999999385327. input_tokens=323, output_tokens=98
18:30:02,11 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:02,13 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.156000000075437. input_tokens=302, output_tokens=102
18:30:02,106 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:02,107 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.265999999945052. input_tokens=335, output_tokens=90
18:30:02,135 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:02,137 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.219000000040978. input_tokens=300, output_tokens=109
18:30:02,139 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:02,140 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.281000000075437. input_tokens=302, output_tokens=111
18:30:02,188 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:02,189 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.3119999999180436. input_tokens=328, output_tokens=102
18:30:02,213 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:02,215 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.281000000075437. input_tokens=298, output_tokens=112
18:30:02,486 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:02,488 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.5929999999934807. input_tokens=312, output_tokens=117
18:30:02,550 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:02,552 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.640999999945052. input_tokens=318, output_tokens=121
18:30:02,669 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:02,671 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.76500000001397. input_tokens=311, output_tokens=130
18:30:02,754 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:02,756 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.8910000000614673. input_tokens=361, output_tokens=157
18:30:03,132 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:03,134 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.234000000054948. input_tokens=320, output_tokens=152
18:30:03,180 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:03,182 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.280999999959022. input_tokens=318, output_tokens=123
18:30:03,239 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:03,241 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.405999999959022. input_tokens=433, output_tokens=216
18:30:03,281 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:03,283 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.469000000040978. input_tokens=400, output_tokens=201
18:30:03,321 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:03,323 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.8119999999180436. input_tokens=292, output_tokens=90
18:30:03,497 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:03,501 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.734000000054948. input_tokens=323, output_tokens=90
18:30:03,519 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:03,521 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.7190000000409782. input_tokens=320, output_tokens=70
18:30:03,575 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:03,581 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.984000000054948. input_tokens=323, output_tokens=95
18:30:03,716 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:03,719 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.187000000034459. input_tokens=310, output_tokens=94
18:30:03,746 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:03,747 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.297000000020489. input_tokens=307, output_tokens=84
18:30:04,100 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:04,101 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.297000000020489. input_tokens=330, output_tokens=101
18:30:04,216 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:04,219 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.765999999945052. input_tokens=311, output_tokens=111
18:30:06,963 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:06,965 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 5.391000000061467. input_tokens=281, output_tokens=92
18:30:07,1 datashaper.workflow.workflow INFO executing verb snapshot_rows
18:30:07,5 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_summarized_entities.parquet
18:30:07,373 graphrag.index.run INFO Running workflow: create_base_entity_graph...
18:30:07,374 graphrag.index.run INFO dependencies for create_base_entity_graph: ['create_summarized_entities']
18:30:07,374 graphrag.index.run INFO read table from storage: create_summarized_entities.parquet
18:30:07,408 datashaper.workflow.workflow INFO executing verb cluster_graph
18:30:07,508 datashaper.workflow.workflow INFO executing verb snapshot_rows
18:30:07,522 datashaper.workflow.workflow INFO executing verb snapshot_rows
18:30:07,534 datashaper.workflow.workflow INFO executing verb select
18:30:07,538 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_entity_graph.parquet
18:30:07,890 graphrag.index.run INFO Running workflow: create_final_entities...
18:30:07,890 graphrag.index.run INFO dependencies for create_final_entities: ['create_base_entity_graph']
18:30:07,891 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
18:30:07,929 datashaper.workflow.workflow INFO executing verb unpack_graph
18:30:07,963 datashaper.workflow.workflow INFO executing verb rename
18:30:07,973 datashaper.workflow.workflow INFO executing verb select
18:30:07,988 datashaper.workflow.workflow INFO executing verb dedupe
18:30:08,5 datashaper.workflow.workflow INFO executing verb rename
18:30:08,20 datashaper.workflow.workflow INFO executing verb filter
18:30:08,67 datashaper.workflow.workflow INFO executing verb text_split
18:30:08,89 datashaper.workflow.workflow INFO executing verb drop
18:30:08,99 datashaper.workflow.workflow INFO executing verb merge
18:30:08,153 datashaper.workflow.workflow INFO executing verb text_embed
18:30:08,156 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.chatanywhere.tech/v1
18:30:09,133 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for text-embedding-3-small: TPM=0, RPM=0
18:30:09,134 graphrag.index.llm.load_llm INFO create concurrency limiter for text-embedding-3-small: 25
18:30:09,164 graphrag.index.verbs.text.embed.strategies.openai INFO embedding 264 inputs via 264 snippets using 17 batches. max_batch_size=16, max_tokens=8191
18:30:09,928 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/embeddings "HTTP/1.1 200 OK"
18:30:09,946 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/embeddings "HTTP/1.1 200 OK"
18:30:09,961 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/embeddings "HTTP/1.1 200 OK"
18:30:10,13 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/embeddings "HTTP/1.1 200 OK"
18:30:10,39 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/embeddings "HTTP/1.1 200 OK"
18:30:10,60 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/embeddings "HTTP/1.1 200 OK"
18:30:10,74 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/embeddings "HTTP/1.1 200 OK"
18:30:10,86 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/embeddings "HTTP/1.1 200 OK"
18:30:10,96 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/embeddings "HTTP/1.1 200 OK"
18:30:10,117 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/embeddings "HTTP/1.1 200 OK"
18:30:10,122 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/embeddings "HTTP/1.1 200 OK"
18:30:10,223 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/embeddings "HTTP/1.1 200 OK"
18:30:10,289 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/embeddings "HTTP/1.1 200 OK"
18:30:10,355 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/embeddings "HTTP/1.1 200 OK"
18:30:10,384 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1880000000819564. input_tokens=261, output_tokens=0
18:30:10,432 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.25. input_tokens=467, output_tokens=0
18:30:10,463 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.2810000000754371. input_tokens=1131, output_tokens=0
18:30:10,484 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.2820000000065193. input_tokens=621, output_tokens=0
18:30:10,520 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.3440000000409782. input_tokens=679, output_tokens=0
18:30:10,539 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/embeddings "HTTP/1.1 200 OK"
18:30:10,543 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.375. input_tokens=979, output_tokens=0
18:30:10,562 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.375. input_tokens=815, output_tokens=0
18:30:10,586 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.3910000000614673. input_tokens=578, output_tokens=0
18:30:10,606 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.4070000000065193. input_tokens=694, output_tokens=0
18:30:10,683 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/embeddings "HTTP/1.1 200 OK"
18:30:10,703 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.5160000000614673. input_tokens=554, output_tokens=0
18:30:10,750 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.5780000000959262. input_tokens=517, output_tokens=0
18:30:10,839 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.6410000000614673. input_tokens=580, output_tokens=0
18:30:11,310 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 2.10999999998603. input_tokens=768, output_tokens=0
18:30:11,329 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 2.156000000075437. input_tokens=765, output_tokens=0
18:30:11,399 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/embeddings "HTTP/1.1 200 OK"
18:30:11,875 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 2.6880000000819564. input_tokens=737, output_tokens=0
18:30:11,899 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 2.7040000000270084. input_tokens=686, output_tokens=0
18:30:11,923 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 2.75. input_tokens=488, output_tokens=0
18:30:11,981 datashaper.workflow.workflow INFO executing verb drop
18:30:12,9 datashaper.workflow.workflow INFO executing verb filter
18:30:12,28 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_entities.parquet
18:30:12,481 graphrag.index.run INFO Running workflow: create_final_nodes...
18:30:12,481 graphrag.index.run INFO dependencies for create_final_nodes: ['create_base_entity_graph']
18:30:12,481 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
18:30:12,518 datashaper.workflow.workflow INFO executing verb layout_graph
18:30:12,680 datashaper.workflow.workflow INFO executing verb unpack_graph
18:30:12,721 datashaper.workflow.workflow INFO executing verb unpack_graph
18:30:12,778 datashaper.workflow.workflow INFO executing verb filter
18:30:12,829 datashaper.workflow.workflow INFO executing verb drop
18:30:12,851 datashaper.workflow.workflow INFO executing verb select
18:30:12,871 datashaper.workflow.workflow INFO executing verb snapshot
18:30:12,894 datashaper.workflow.workflow INFO executing verb rename
18:30:12,912 datashaper.workflow.workflow INFO executing verb join
18:30:12,952 datashaper.workflow.workflow INFO executing verb convert
18:30:13,55 datashaper.workflow.workflow INFO executing verb rename
18:30:13,58 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_nodes.parquet
18:30:13,475 graphrag.index.run INFO Running workflow: create_final_communities...
18:30:13,475 graphrag.index.run INFO dependencies for create_final_communities: ['create_base_entity_graph']
18:30:13,475 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
18:30:13,519 datashaper.workflow.workflow INFO executing verb unpack_graph
18:30:13,576 datashaper.workflow.workflow INFO executing verb unpack_graph
18:30:13,625 datashaper.workflow.workflow INFO executing verb aggregate_override
18:30:13,653 datashaper.workflow.workflow INFO executing verb join
18:30:13,677 datashaper.workflow.workflow INFO executing verb join
18:30:13,711 datashaper.workflow.workflow INFO executing verb concat
18:30:13,729 datashaper.workflow.workflow INFO executing verb filter
18:30:13,810 datashaper.workflow.workflow INFO executing verb aggregate_override
18:30:13,838 datashaper.workflow.workflow INFO executing verb join
18:30:13,865 datashaper.workflow.workflow INFO executing verb filter
18:30:13,910 datashaper.workflow.workflow INFO executing verb fill
18:30:13,936 datashaper.workflow.workflow INFO executing verb merge
18:30:13,965 datashaper.workflow.workflow INFO executing verb copy
18:30:13,988 datashaper.workflow.workflow INFO executing verb select
18:30:13,992 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_communities.parquet
18:30:14,410 graphrag.index.run INFO Running workflow: join_text_units_to_entity_ids...
18:30:14,410 graphrag.index.run INFO dependencies for join_text_units_to_entity_ids: ['create_final_entities']
18:30:14,410 graphrag.index.run INFO read table from storage: create_final_entities.parquet
18:30:14,479 datashaper.workflow.workflow INFO executing verb select
18:30:14,500 datashaper.workflow.workflow INFO executing verb unroll
18:30:14,526 datashaper.workflow.workflow INFO executing verb aggregate_override
18:30:14,531 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_entity_ids.parquet
18:30:14,878 graphrag.index.run INFO Running workflow: create_final_relationships...
18:30:14,878 graphrag.index.run INFO dependencies for create_final_relationships: ['create_base_entity_graph', 'create_final_nodes']
18:30:14,878 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
18:30:14,881 graphrag.index.run INFO read table from storage: create_final_nodes.parquet
18:30:14,925 datashaper.workflow.workflow INFO executing verb unpack_graph
18:30:14,964 datashaper.workflow.workflow INFO executing verb filter
18:30:15,12 datashaper.workflow.workflow INFO executing verb rename
18:30:15,33 datashaper.workflow.workflow INFO executing verb filter
18:30:15,84 datashaper.workflow.workflow INFO executing verb drop
18:30:15,109 datashaper.workflow.workflow INFO executing verb compute_edge_combined_degree
18:30:15,128 datashaper.workflow.workflow INFO executing verb convert
18:30:15,157 datashaper.workflow.workflow INFO executing verb convert
18:30:15,159 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_relationships.parquet
18:30:15,528 graphrag.index.run INFO Running workflow: join_text_units_to_relationship_ids...
18:30:15,531 graphrag.index.run INFO dependencies for join_text_units_to_relationship_ids: ['create_final_relationships']
18:30:15,532 graphrag.index.run INFO read table from storage: create_final_relationships.parquet
18:30:15,583 datashaper.workflow.workflow INFO executing verb select
18:30:15,599 datashaper.workflow.workflow INFO executing verb unroll
18:30:15,616 datashaper.workflow.workflow INFO executing verb aggregate_override
18:30:15,636 datashaper.workflow.workflow INFO executing verb select
18:30:15,638 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_relationship_ids.parquet
18:30:15,981 graphrag.index.run INFO Running workflow: create_final_community_reports...
18:30:15,981 graphrag.index.run INFO dependencies for create_final_community_reports: ['create_final_relationships', 'create_final_nodes']
18:30:15,982 graphrag.index.run INFO read table from storage: create_final_relationships.parquet
18:30:15,987 graphrag.index.run INFO read table from storage: create_final_nodes.parquet
18:30:16,40 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
18:30:16,68 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
18:30:16,88 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
18:30:16,108 datashaper.workflow.workflow INFO executing verb prepare_community_reports
18:30:16,108 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=1 => 264
18:30:16,153 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 264
18:30:16,210 datashaper.workflow.workflow INFO executing verb create_community_reports
18:30:26,304 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:26,305 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.062999999965541. input_tokens=1808, output_tokens=730
18:30:26,568 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:26,569 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.311999999918044. input_tokens=1863, output_tokens=751
18:30:26,937 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:26,938 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.71799999999348. input_tokens=1831, output_tokens=718
18:30:27,292 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:27,293 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.062000000034459. input_tokens=2286, output_tokens=808
18:30:27,592 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:27,593 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.344000000040978. input_tokens=2180, output_tokens=822
18:30:28,153 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:28,155 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.922000000020489. input_tokens=1775, output_tokens=823
18:30:28,184 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:28,185 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.937999999965541. input_tokens=1756, output_tokens=803
18:30:28,278 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:28,279 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.015999999945052. input_tokens=1897, output_tokens=877
18:30:29,350 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:29,351 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 13.10999999998603. input_tokens=2309, output_tokens=923
18:30:38,611 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:38,613 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.233999999938533. input_tokens=2174, output_tokens=790
18:30:39,100 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:39,101 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.702999999979511. input_tokens=2614, output_tokens=859
18:30:41,544 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:41,546 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.125. input_tokens=2064, output_tokens=844
18:30:41,716 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:41,718 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.312000000034459. input_tokens=2152, output_tokens=852
18:30:42,135 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:42,136 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.75. input_tokens=2529, output_tokens=893
18:30:42,239 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:42,241 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.84299999999348. input_tokens=2502, output_tokens=914
18:30:42,787 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:42,789 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 13.405999999959022. input_tokens=2520, output_tokens=968
18:30:42,883 httpx INFO HTTP Request: POST https://api.chatanywhere.tech/v1/chat/completions "HTTP/1.1 200 OK"
18:30:42,884 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 13.484000000054948. input_tokens=3413, output_tokens=973
18:30:42,903 datashaper.workflow.workflow INFO executing verb window
18:30:42,906 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_community_reports.parquet
18:30:43,300 graphrag.index.run INFO Running workflow: create_final_text_units...
18:30:43,301 graphrag.index.run INFO dependencies for create_final_text_units: ['create_base_text_units', 'join_text_units_to_relationship_ids', 'join_text_units_to_entity_ids']
18:30:43,301 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
18:30:43,305 graphrag.index.run INFO read table from storage: join_text_units_to_relationship_ids.parquet
18:30:43,316 graphrag.index.run INFO read table from storage: join_text_units_to_entity_ids.parquet
18:30:43,377 datashaper.workflow.workflow INFO executing verb select
18:30:43,401 datashaper.workflow.workflow INFO executing verb rename
18:30:43,425 datashaper.workflow.workflow INFO executing verb join
18:30:43,452 datashaper.workflow.workflow INFO executing verb join
18:30:43,480 datashaper.workflow.workflow INFO executing verb aggregate_override
18:30:43,508 datashaper.workflow.workflow INFO executing verb select
18:30:43,510 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_text_units.parquet
18:30:43,888 graphrag.index.run INFO Running workflow: create_base_documents...
18:30:43,888 graphrag.index.run INFO dependencies for create_base_documents: ['create_final_text_units']
18:30:43,889 graphrag.index.run INFO read table from storage: create_final_text_units.parquet
18:30:43,942 datashaper.workflow.workflow INFO executing verb unroll
18:30:43,963 datashaper.workflow.workflow INFO executing verb select
18:30:43,990 datashaper.workflow.workflow INFO executing verb rename
18:30:44,16 datashaper.workflow.workflow INFO executing verb join
18:30:44,47 datashaper.workflow.workflow INFO executing verb aggregate_override
18:30:44,77 datashaper.workflow.workflow INFO executing verb join
18:30:44,108 datashaper.workflow.workflow INFO executing verb rename
18:30:44,136 datashaper.workflow.workflow INFO executing verb convert
18:30:44,161 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_documents.parquet
18:30:44,525 graphrag.index.run INFO Running workflow: create_final_documents...
18:30:44,538 graphrag.index.run INFO dependencies for create_final_documents: ['create_base_documents']
18:30:44,538 graphrag.index.run INFO read table from storage: create_base_documents.parquet
18:30:44,599 datashaper.workflow.workflow INFO executing verb rename
18:30:44,601 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_documents.parquet
